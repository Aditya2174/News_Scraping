{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For a Data Scientist to be truly succesful, he must be adept at all aspects of his craft.\n",
        "The first and the most important step for a data scientist in his/her project is to collect high quality data. As we all know, high quality data makes a high quality model.\n",
        "\n",
        "In this task, you are to use web scraping techniques to collect news data from timesofindia.com from the various cities that are available on the website.\n",
        "\n",
        "you should use beautifulsoup library for web scraping"
      ],
      "metadata": {
        "id": "_woEk3bFDN-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries here\n"
      ],
      "metadata": {
        "id": "hCtHw-74D_md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use libraries to pull data from website\n"
      ],
      "metadata": {
        "id": "oOzVF8-PiIIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#SUBTASK 1**\n",
        "\n",
        "you are tasked to build a dataset in .csv format\n",
        "expected features in the dataset are\n",
        "\n",
        "[Headline,Description,Date Posted,City, Category, URL]\n",
        "\n",
        "any further features that can be extracted can be added"
      ],
      "metadata": {
        "id": "7ar6IMQPFfLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logic goes here\n"
      ],
      "metadata": {
        "id": "yCyFa-dYHQsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBTASK 2**\n",
        "\n",
        "Now that the data is collected, it is your job to clean it and store it in a way such that model can be trained efficiently.\n",
        "Perform EDA on your scraped data and try to create a high quality dataset\n",
        "some characteristics of a high quality dataset include:\n",
        "\n",
        "1.   balanced dataset, each class should have an almost equal number of samples\n",
        "2.   diverse, try and gather as many varying data points for each class\n",
        "3.   keep the data as accurate as possible\n",
        "\n",
        "EDA is usually performed by using graphs and charts to visualize the data points"
      ],
      "metadata": {
        "id": "JhXmNHF8HWxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#logic goes here\n"
      ],
      "metadata": {
        "id": "FJzIrHhaJDIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SUBTASK 3**\n",
        "\n",
        "Excel sheets, csv files and JSON files are good to store datasets which are small, how do you store data that spans millions, if not billions of rows?\n",
        "The answer to this is a database. Those of you with sufficient knowledge of sql and databases can opt to store your csv files in any database of your choice"
      ],
      "metadata": {
        "id": "vp6V7wLuJJot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n"
      ],
      "metadata": {
        "id": "abNryviRJlQO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}